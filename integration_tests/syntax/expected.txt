Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {t}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {ta}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {txa}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {someName}
Token: TOKEN_COMMENT Text: {// some comment}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_PARTIAL
Token: TOKEN_NEWLINE
Token: TOKEN_MODULE
Token: TOKEN_NEWLINE
Token: TOKEN_IMPORT
Token: TOKEN_NEWLINE
Token: TOKEN_EXPORT
Token: TOKEN_NEWLINE
Token: TOKEN_RETURN
Token: TOKEN_NEWLINE
Token: TOKEN_MATCH
Token: TOKEN_NEWLINE
Token: TOKEN_FALSE
Token: TOKEN_NEWLINE
Token: TOKEN_TYPE
Token: TOKEN_NEWLINE
Token: TOKEN_TRUE
Token: TOKEN_NEWLINE
Token: TOKEN_THIS
Token: TOKEN_NEWLINE
Token: TOKEN_AND
Token: TOKEN_NEWLINE
Token: TOKEN_TRY
Token: TOKEN_NEWLINE
Token: TOKEN_OR
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_BINARY Text: {0b0100_1011}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_OCTAL Text: {0o0123_4567}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_HEX Text: {0x0234_5678_9Abc_DeFF}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER Text: {1234}
Token: TOKEN_NUMBER Text: {1_234}
Token: TOKEN_NUMBER_FLOAT Text: {1_234.322}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER Text: {1_000_000u64}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_BINARY Text: {0b1010_1100u8}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_HEX Text: {0xDEAD_BEEFu16}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER Text: {42i32}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_FLOAT Text: {3.14f64}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER Text: {100i128}
Token: TOKEN_NEWLINE
Token: TOKEN_NUMBER_FLOAT Text: {2.5f32}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COLON
Token: TOKEN_SEMICOLON
Token: TOKEN_COMMA
Token: TOKEN_DOT
Token: TOKEN_PIPE
Token: TOKEN_UNDERSCORE
Token: TOKEN_STAR
Token: TOKEN_LPAREN
Token: TOKEN_RPAREN
Token: TOKEN_LBRACE
Token: TOKEN_RBRACE
Token: TOKEN_LBRACKET
Token: TOKEN_RBRACKET
Token: TOKEN_LANGLE
Token: TOKEN_RANGLE
Token: TOKEN_PLUS
Token: TOKEN_MINUS
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_STRING Text: {""}
Token: TOKEN_NEWLINE
Token: TOKEN_STRING Text: {"this ia a text\n"}
Token: TOKEN_NEWLINE
Token: TOKEN_STRING Text: {''}
Token: TOKEN_NEWLINE
Token: TOKEN_STRING Text: {'this is another text\n'}
Token: TOKEN_NEWLINE
Token: TOKEN_DOCUMENTATION Text: {============
============}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_DOCUMENTATION Text: {====
this is documentation
....
====}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COMMENT Text: {// Test single backtick interpolation}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {greeting}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {1}
Token: TOKEN_STRING_I Text: {Hello }
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {name}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I Text: {!}
Token: TOKEN_STRING_I_END Text: {1}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {other}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {1}
Token: TOKEN_STRING_I Text: {this is a {}
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {name}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I Text: {}}
Token: TOKEN_STRING_I_END Text: {1}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COMMENT Text: {// Test empty string}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {empty}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {1}
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I_END Text: {1}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COMMENT Text: {// Test double backticks}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {message}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {2}
Token: TOKEN_STRING_I Text: {Welcome }
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {user}
Token: TOKEN_DOT
Token: TOKEN_IDENTIFIER Text: {name}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I Text: {!}
Token: TOKEN_STRING_I_END Text: {2}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COMMENT Text: {// Test triple backticks}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {report}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {3}
Token: TOKEN_STRING_I Text: {Items: }
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {count}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I_END Text: {3}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COMMENT Text: {// Test multiline single backtick}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {multiline}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {1}
Token: TOKEN_STRING_I Text: {    Hello }
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {name}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I Text: {!
    How are you?}
Token: TOKEN_STRING_I_INDENT Text: {    }
Token: TOKEN_STRING_I_END Text: {1}
Token: TOKEN_NEWLINE
Token: TOKEN_NEWLINE
Token: TOKEN_COMMENT Text: {// Test multiline double backticks}
Token: TOKEN_NEWLINE
Token: TOKEN_IDENTIFIER Text: {complex}
Token: TOKEN_COLON
Token: TOKEN_STRING_I_START Text: {2}
Token: TOKEN_STRING_I Text: {    User: }
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {user}
Token: TOKEN_DOT
Token: TOKEN_IDENTIFIER Text: {name}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I Text: {
    Balance: $}
Token: TOKEN_STRING_I_EXPR_START
Token: TOKEN_IDENTIFIER Text: {user}
Token: TOKEN_DOT
Token: TOKEN_IDENTIFIER Text: {balance}
Token: TOKEN_STRING_I_EXPR_END
Token: TOKEN_STRING_I_INDENT Text: {    }
Token: TOKEN_STRING_I_END Text: {2}
Token: TOKEN_NEWLINE
